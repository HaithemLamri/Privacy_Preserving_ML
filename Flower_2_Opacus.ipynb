{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBu1HRRY6bwX"
      },
      "source": [
        "<h1>Opacus : Train PyTorch models with Differential Privacy </h1>\n",
        "Opacus is a pytorch-based framework,it was developped by Meta AI to allow us to train our models with differential privacy, and this is by transforming any SGD based optimization algorithm to its variant DP-SGD, the idea of DP-SGD is adding gaussian noise and performing gradient clipping to the gradients and using the poisson batch selection shceme, Opacus provides also the tracking the DP budget during the training.\n",
        "Note that Opacus allow us to make only local differential privacy which is useful for defending against the distributed backdoor attack, and in order to perform a global differential privacy architecture, we have to make some modifications on the strategy and add gaussian noises to the model updates before aggregating them.<br>\n",
        "\n",
        "<h3>Ressources</h3>\n",
        "<ul>\n",
        "  <li> <a href=\"https://youtu.be/U1mszp8lzUI\"> An intro video </a></li>\n",
        "<li> <a href=\"https://opacus.ai/\"> Opacus website</a></li>\n",
        "<li> <a href=\"http://dimacs.rutgers.edu/~graham/pubs/papers/opacus.pdf\"> Opacus research paper</a></li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4KiTMTpiort"
      },
      "source": [
        "### Installing dependencies\n",
        "\n",
        "First, we install the necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TbEeAvpx2jFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a46cb5-145f-4c50-c669-c886726f0371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.9/216.9 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.5/90.5 KB\u001b[0m \u001b[31m353.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision opacus\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aD90nw-qqvIv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abtAKdBl6in6"
      },
      "source": [
        "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eTrCL2FmC5U5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f134b430-e59d-40cb-cbdd-ac727d7965ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 1.13.1+cu116 and Flower 1.3.0\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import warnings\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.models import vgg11,vgg16,resnet18\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.simplefilter(\"ignore\")\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D2bnPKG58Gx"
      },
      "source": [
        "It is possible to switch to a runtime that has GPU acceleration enabled (on Google Colab: `Runtime > Change runtime type > Hardware acclerator: GPU > Save`). Note, however, that Google Colab is not always able to offer GPU acceleration. If you see an error related to GPU availability in one of the following sections, consider switching back to CPU-based execution by setting `DEVICE = torch.device(\"cpu\")`. If the runtime has GPU acceleration enabled, you should see the output `Training on cuda:0`, otherwise it'll say `Training on cpu`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcgAAiaihnx"
      },
      "source": [
        "### Data loading\n",
        "\n",
        "Let's now load the CIFAR-10 training and test set, partition them into ten smaller datasets (each split into training and validation set), and wrap everything in their own `DataLoader`. We introduce a new parameter `num_clients` which allows us to call `load_datasets` with different numbers of clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J4Em7BPNTXeX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def load_datasets(num_clients: int):\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose(\n",
        "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    partition_size = len(trainset) // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
        "    testloader = DataLoader(testset, batch_size=16)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HeURxZem5D6g"
      },
      "outputs": [],
      "source": [
        "from opacus import PrivacyEngine\n",
        "MAX_GRAD_NORM = 1.\n",
        "EPSILON = 20.0\n",
        "DELTA = 1e-5\n",
        "EPOCHS = 6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBp7kB4G0sPB"
      },
      "source": [
        "### Model training/evaluation\n",
        "\n",
        "Let's continue with the usual model definition (including `set_parameters` and `get_parameters`), training and test functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2X3cVBXMpP6w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x )  :\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "MAX_PHYSICAL_BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "def train(model, train_loader, optimizer, privacy_engine,epoch, device):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    losses = []\n",
        "    top1_acc = []\n",
        "    \n",
        "    with BatchMemoryManager(\n",
        "        data_loader=train_loader, \n",
        "        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE, \n",
        "        optimizer=optimizer\n",
        "    ) as memory_safe_data_loader:\n",
        "\n",
        "        for i, (images, target) in enumerate(memory_safe_data_loader): \n",
        "            optimizer.zero_grad()\n",
        "            images = images.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # compute output\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
        "            labels = target.detach().cpu().numpy()\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            acc = (preds == labels).mean()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            top1_acc.append(acc)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (i+1) % 200 == 0:\n",
        "                          epsilon = privacy_engine.get_epsilon(DELTA)\n",
        "                          print(\n",
        "                              f\"\\tTrain Epoch: {epoch} \\t\"\n",
        "                              f\"Loss: {np.mean(losses):.6f} \"\n",
        "                              f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
        "                              f\"(ε = {epsilon:.2f}, δ = {DELTA})\"\n",
        "                          )\n",
        "                  \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def test(net, testloader,device:str):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    #net.to(\"cpu\")\n",
        "    return loss, accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fXW0Faf4dv-0"
      },
      "outputs": [],
      "source": [
        "\n",
        "                 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAlxDtSXH6dy"
      },
      "source": [
        "<h2>NN layers and DP</h2>\n",
        "Certain nn.Modules are not compatible with differential privacy! One of them is the popular BatchNorm layer (the reason being that it would require to make even the forward loop privacy-aware, because now each sample's feature depends on its peers in a batch). While we could do it, we don't think BatchNorm is worth the hassle.\n",
        "\n",
        "Opacus comes with a utility to convert BatchNorm models to GroupNorm, which does not have this issue (you can of course also convert them to InstanceNorm, or LayerNorm but let's stick to GroupNorm since it's a generalization of those two anyway).\n",
        "\n",
        "\n",
        "source : <a href=\"https://colab.research.google.com/drive18GRMyixn43T_lHF6ZheoAJn4-J8L3LAL#scrollTo=1f6H4PI7Ndgb\" >Opacus demo</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSIPML-5Ioab"
      },
      "source": [
        "We can check the validity of our model, and if it contains some incompatible layers we can then fix them using the validator function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ICYYcnrcAj9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238c07e7-2041-4dd3-d98a-790375c40739"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from opacus.validators import ModuleValidator\n",
        "\n",
        "errors = ModuleValidator.validate(Net(), strict=False)\n",
        "errors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lCf3oljdClM"
      },
      "source": [
        "### Flower client\n",
        "\n",
        "To implement the Flower client, we (again) create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`. Here, we also pass the `cid` to the client and use it log additional details:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ye6Jt5p3LWtF"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(\"ignore\")\n",
        "class FlowerClientDP(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.device = torch.device(f\"cuda:{int(self.cid)%4}\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.net.to(self.device)\n",
        "        self.privacy_engine  = PrivacyEngine(secure_mode=False)\n",
        "        self.optimizer = torch.optim.SGD(self.net.parameters(), lr = 0.001)\n",
        "        self.net, self.optimizer, self.trainloader = self.privacy_engine.make_private_with_epsilon(\n",
        "                                                      module=self.net,\n",
        "                                                      optimizer=self.optimizer,\n",
        "                                                      data_loader=self.trainloader,\n",
        "                                                      epochs=1,\n",
        "                                                      target_epsilon=EPSILON,\n",
        "                                                      target_delta=DELTA,\n",
        "                                                      max_grad_norm=MAX_GRAD_NORM,\n",
        "                                                  )   \n",
        "\n",
        "        #change net.params here\n",
        "        \n",
        "       \n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        params = get_parameters(self.net)\n",
        "        \n",
        "        return params\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "     \n",
        "        for _ in range(EPOCHS):\n",
        "          train(self.net, self.trainloader, self.optimizer ,self.privacy_engine,epoch=_,device = self.device)\n",
        "        epsilon = self.privacy_engine.get_epsilon(DELTA)\n",
        "        print(f\"epsilon of client {self.cid} : eps = {epsilon}\")\n",
        "        return get_parameters(self.net), len(self.trainloader), {\"epsilon\" : epsilon}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader,device = self.device)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClientDP:\n",
        "    device = torch.device(f\"cuda:{int(cid)%4}\" if torch.cuda.is_available() else \"cpu\")\n",
        "    net = Net()\n",
        "    net = net.to(device)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    \n",
        "    \n",
        "\n",
        "    return FlowerClientDP(cid, net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6HP2cYCsqxD"
      },
      "source": [
        "## Strategy customization\n",
        "\n",
        "So far, everything should look familiar if you've worked through the introductory notebook. With that, we're ready to introduce a number of new features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt3_SmQKnpRO"
      },
      "source": [
        "## Server-side parameter **evaluation**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hMYIsfsT8wu4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "6648616fbe7a4280945e57de1277e30c",
            "cc76aa5f101946f2920747a661659ef6",
            "672162bb77a2426eafd3e73af4e29234",
            "aeb6a80e16534aaf9ade4e7b6c9147fd",
            "569f1567ffcf4e12867239dc20e93d3b",
            "7c106229a7524eb8ac191c162ece4fbd",
            "7b1828db76404ac6ab0b9b0d65cb210b",
            "78d56869bb524a688b77970084884ee8",
            "588a11d7872a4f0daa780431fbba6088",
            "f82560a209d6453682b5a5d007b703b0",
            "15595f5ff69d4f6db996ad7313626ef1"
          ]
        },
        "outputId": "d4f2d7b0-3803-43e4-b2e1-560cea3109ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6648616fbe7a4280945e57de1277e30c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "NUM_CLIENTS = 10\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k2M493jUPjKG"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(\"ignore\")\n",
        "net = Net()\n",
        "net.to(DEVICE)\n",
        "privacy_engine = PrivacyEngine(secure_mode=False)\n",
        "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01)\n",
        "\n",
        "net, optimizer, trainloader = privacy_engine.make_private_with_epsilon(\n",
        "                                                      module=net,\n",
        "                                                      optimizer=optimizer,\n",
        "                                                      data_loader=trainloaders[0],\n",
        "                                                      epochs=1,\n",
        "                                                      target_epsilon=EPSILON,\n",
        "                                                      target_delta=DELTA,\n",
        "                                                      max_grad_norm=MAX_GRAD_NORM,\n",
        "                                                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MDovnUvsn7if"
      },
      "outputs": [],
      "source": [
        "# The `evaluate` function will be by Flower called after every round\n",
        "\n",
        "global_model = Net() \n",
        "\n",
        "global_model = global_model.to(DEVICE) \n",
        "params = get_parameters(global_model)\n",
        "def evaluate(\n",
        "    server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar]\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    valloader = valloaders[0]\n",
        "    set_parameters(global_model, parameters)  # Update model with the latest parameters\n",
        "    loss, accuracy = test(global_model, valloader,DEVICE)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5aGRnyQnu0Z",
        "outputId": "76aa2a74-4010-4d5c-ad9d-e73099683e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-02-16 12:46:57,525 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "2023-02-16 12:46:59,346\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "INFO flwr 2023-02-16 12:47:00,688 | app.py:179 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 3992779161.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0, 'memory': 7985558324.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 3992779161.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0, 'memory': 7985558324.0}\n",
            "INFO flwr 2023-02-16 12:47:00,697 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-02-16 12:47:00,704 | server.py:266 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2023-02-16 12:47:00,711 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-02-16 12:47:01,097 | server.py:91 | initial parameters (loss, other metrics): 0.07371957349777222, {'accuracy': 0.1}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 0.07371957349777222, {'accuracy': 0.1}\n",
            "INFO flwr 2023-02-16 12:47:01,102 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-02-16 12:47:01,112 | server.py:215 | fit_round 1: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07371957349777222 / accuracy 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m /usr/local/lib/python3.8/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m /usr/local/lib/python3.8/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m /usr/local/lib/python3.8/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m   z = np.log((np.exp(t) + q - 1) / q)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m /usr/local/lib/python3.8/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m /usr/local/lib/python3.8/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m /usr/local/lib/python3.8/dist-packages/opacus/accountants/analysis/prv/prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m   z = np.log((np.exp(t) + q - 1) / q)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m   warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 2] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1117: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m   warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.305388 Acc@1: 9.236288 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.302753 Acc@1: 9.657957 (ε = 19.95, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.305431 Acc@1: 8.728929 (ε = 25.00, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.302460 Acc@1: 10.133970 (ε = 25.03, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.303768 Acc@1: 9.238302 (ε = 28.84, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.302049 Acc@1: 10.136234 (ε = 32.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.305551 Acc@1: 8.047384 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.304110 Acc@1: 9.307872 (ε = 35.63, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.304025 Acc@1: 8.487548 (ε = 38.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 4 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 2 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.303750 Acc@1: 10.178514 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.303110 Acc@1: 10.955836 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.303411 Acc@1: 10.454047 (ε = 24.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.302388 Acc@1: 10.373301 (ε = 24.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.302125 Acc@1: 10.720992 (ε = 28.92, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.301951 Acc@1: 9.880747 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.302719 Acc@1: 9.112485 (ε = 35.41, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.302002 Acc@1: 10.148151 (ε = 35.56, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.301282 Acc@1: 10.354100 (ε = 38.39, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.301808 Acc@1: 10.834835 (ε = 38.56, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 9 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 8 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.302705 Acc@1: 10.933051 (ε = 19.91, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.303605 Acc@1: 9.908142 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.303707 Acc@1: 9.924903 (ε = 24.90, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.304953 Acc@1: 9.469416 (ε = 32.31, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.303892 Acc@1: 10.487872 (ε = 32.45, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.302424 Acc@1: 9.383281 (ε = 35.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.303340 Acc@1: 10.289466 (ε = 35.65, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.303960 Acc@1: 10.392569 (ε = 38.45, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 1 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 3 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.302244 Acc@1: 9.763121 (ε = 19.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.301612 Acc@1: 9.886092 (ε = 28.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.302789 Acc@1: 9.993665 (ε = 32.36, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.302453 Acc@1: 9.536333 (ε = 35.48, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.301794 Acc@1: 9.433150 (ε = 38.54, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 12:51:55,055 | server.py:229 | fit_round 1 received 7 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 7 results and 0 failures\n",
            "WARNING flwr 2023-02-16 12:51:55,097 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 7 : eps = 38.57552953833644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-02-16 12:51:55,323 | server.py:116 | fit progress: (1, 0.07369145441055298, {'accuracy': 0.1}, 294.211056659)\n",
            "INFO:flwr:fit progress: (1, 0.07369145441055298, {'accuracy': 0.1}, 294.211056659)\n",
            "DEBUG flwr 2023-02-16 12:51:55,327 | server.py:165 | evaluate_round 1: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07369145441055298 / accuracy 0.1\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 12:53:00,650 | server.py:179 | evaluate_round 1 received 7 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 7 results and 0 failures\n",
            "WARNING flwr 2023-02-16 12:53:00,656 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-02-16 12:53:00,660 | server.py:215 | fit_round 2: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.302507 Acc@1: 10.582067 (ε = 19.74, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.299718 Acc@1: 11.394659 (ε = 24.90, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.303885 Acc@1: 9.299317 (ε = 24.90, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.302589 Acc@1: 10.522812 (ε = 32.38, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.301446 Acc@1: 10.155468 (ε = 35.41, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.301186 Acc@1: 10.583005 (ε = 35.48, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.300153 Acc@1: 10.534283 (ε = 38.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.301649 Acc@1: 9.846465 (ε = 38.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 8 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 3 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.301476 Acc@1: 10.431480 (ε = 19.82, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.301796 Acc@1: 10.124044 (ε = 25.03, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.302057 Acc@1: 9.380278 (ε = 25.03, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.301948 Acc@1: 10.061749 (ε = 28.94, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.300446 Acc@1: 10.012587 (ε = 28.86, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.300813 Acc@1: 10.103399 (ε = 32.38, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.300901 Acc@1: 10.158317 (ε = 38.37, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.301591 Acc@1: 8.056696 (ε = 38.43, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 0 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 7 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.301411 Acc@1: 10.626580 (ε = 19.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.303672 Acc@1: 10.077174 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.301068 Acc@1: 10.542179 (ε = 24.81, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.302205 Acc@1: 10.362750 (ε = 24.93, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.301450 Acc@1: 10.066567 (ε = 28.84, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.301916 Acc@1: 9.997781 (ε = 28.94, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.301670 Acc@1: 9.990404 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.301605 Acc@1: 10.074041 (ε = 32.43, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.300948 Acc@1: 9.982301 (ε = 35.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.301117 Acc@1: 9.923845 (ε = 35.61, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.299364 Acc@1: 10.715243 (ε = 38.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 6 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 9 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.301586 Acc@1: 10.947784 (ε = 24.68, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.301481 Acc@1: 10.279590 (ε = 28.99, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.300672 Acc@1: 11.658488 (ε = 32.36, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.300103 Acc@1: 10.546375 (ε = 35.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.300349 Acc@1: 10.980224 (ε = 38.50, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 12:57:47,155 | server.py:229 | fit_round 2 received 7 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 7 results and 0 failures\n",
            "INFO flwr 2023-02-16 12:57:47,336 | server.py:116 | fit progress: (2, 0.07366289901733399, {'accuracy': 0.1}, 646.224924443)\n",
            "INFO:flwr:fit progress: (2, 0.07366289901733399, {'accuracy': 0.1}, 646.224924443)\n",
            "DEBUG flwr 2023-02-16 12:57:47,341 | server.py:165 | evaluate_round 2: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 5 : eps = 38.57552953833644\n",
            "Server-side evaluation loss 0.07366289901733399 / accuracy 0.1\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 5] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 12:58:51,804 | server.py:179 | evaluate_round 2 received 7 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 7 results and 0 failures\n",
            "DEBUG flwr 2023-02-16 12:58:51,810 | server.py:215 | fit_round 3: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.300641 Acc@1: 10.268540 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.301696 Acc@1: 9.323455 (ε = 19.82, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.300969 Acc@1: 9.790920 (ε = 24.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.300319 Acc@1: 10.148369 (ε = 24.75, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.300151 Acc@1: 10.060660 (ε = 28.92, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.300784 Acc@1: 9.947568 (ε = 28.86, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.300705 Acc@1: 9.684944 (ε = 32.31, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.299898 Acc@1: 10.895550 (ε = 32.47, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.299480 Acc@1: 10.808631 (ε = 35.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.299785 Acc@1: 9.831325 (ε = 35.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.298262 Acc@1: 9.937866 (ε = 38.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 4 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 9 : eps = 38.57552953833644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 2794 MiB, 37 objects, write throughput 201 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.301214 Acc@1: 8.930246 (ε = 19.82, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.299391 Acc@1: 9.565211 (ε = 24.75, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.300313 Acc@1: 9.666892 (ε = 24.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.298855 Acc@1: 9.764071 (ε = 28.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.298841 Acc@1: 9.778669 (ε = 32.43, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.299393 Acc@1: 9.686818 (ε = 32.36, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.299683 Acc@1: 9.692947 (ε = 35.56, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.298698 Acc@1: 10.591441 (ε = 35.48, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.299985 Acc@1: 10.160615 (ε = 38.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.297741 Acc@1: 10.252314 (ε = 38.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 1 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 7 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.301989 Acc@1: 10.326425 (ε = 19.65, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.301004 Acc@1: 9.820695 (ε = 19.95, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.301705 Acc@1: 9.490835 (ε = 24.75, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.302321 Acc@1: 8.723815 (ε = 24.90, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.300555 Acc@1: 10.436661 (ε = 28.99, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.301210 Acc@1: 8.826613 (ε = 32.36, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.300367 Acc@1: 10.239583 (ε = 32.36, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.300179 Acc@1: 8.738778 (ε = 35.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.300047 Acc@1: 10.881231 (ε = 38.41, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 2 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 3 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.301194 Acc@1: 10.118699 (ε = 19.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.298888 Acc@1: 11.264093 (ε = 28.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.300407 Acc@1: 10.606496 (ε = 32.38, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.299444 Acc@1: 10.172297 (ε = 35.58, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:04:05,787 | server.py:229 | fit_round 3 received 7 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 7 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 5 : eps = 38.57552953833644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-02-16 13:04:06,290 | server.py:116 | fit progress: (3, 0.07362965869903565, {'accuracy': 0.1}, 1025.178065114)\n",
            "INFO:flwr:fit progress: (3, 0.07362965869903565, {'accuracy': 0.1}, 1025.178065114)\n",
            "DEBUG flwr 2023-02-16 13:04:06,295 | server.py:165 | evaluate_round 3: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07362965869903565 / accuracy 0.1\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 8] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:05:19,603 | server.py:179 | evaluate_round 3 received 7 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 7 results and 0 failures\n",
            "DEBUG flwr 2023-02-16 13:05:19,610 | server.py:215 | fit_round 4: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 7 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 4265 MiB, 54 objects, write throughput 203 MiB/s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.299015 Acc@1: 10.237564 (ε = 19.95, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.298247 Acc@1: 10.948779 (ε = 19.69, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.298544 Acc@1: 10.161113 (ε = 24.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.298212 Acc@1: 10.681090 (ε = 24.84, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.297379 Acc@1: 11.235405 (ε = 28.92, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.296968 Acc@1: 11.200479 (ε = 28.68, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.297001 Acc@1: 11.432730 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.297504 Acc@1: 10.649984 (ε = 32.38, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.298052 Acc@1: 10.003862 (ε = 35.65, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.298145 Acc@1: 9.989669 (ε = 35.56, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.298651 Acc@1: 10.470711 (ε = 38.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.298517 Acc@1: 10.108774 (ε = 38.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 8 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 5 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.299522 Acc@1: 9.525607 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.299106 Acc@1: 11.414354 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.297610 Acc@1: 10.584492 (ε = 25.00, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.299224 Acc@1: 10.346133 (ε = 24.90, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.297123 Acc@1: 10.260171 (ε = 28.94, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.298806 Acc@1: 10.164646 (ε = 28.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.297808 Acc@1: 9.815095 (ε = 32.33, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.298641 Acc@1: 10.342449 (ε = 35.39, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.297093 Acc@1: 9.582787 (ε = 35.61, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.297791 Acc@1: 10.650338 (ε = 38.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.297821 Acc@1: 9.480990 (ε = 38.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 3 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 7 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.297529 Acc@1: 10.936342 (ε = 19.74, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.297666 Acc@1: 10.979025 (ε = 24.93, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.299149 Acc@1: 10.010524 (ε = 28.99, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.299452 Acc@1: 9.235903 (ε = 32.36, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.298746 Acc@1: 10.365225 (ε = 35.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.296393 Acc@1: 10.565838 (ε = 35.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.297243 Acc@1: 9.858623 (ε = 38.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 4 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.297786 Acc@1: 10.599404 (ε = 38.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 9 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.299166 Acc@1: 10.714031 (ε = 24.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.299271 Acc@1: 10.063968 (ε = 32.33, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.298283 Acc@1: 11.136268 (ε = 38.41, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:10:33,947 | server.py:229 | fit_round 4 received 7 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 7 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 6 : eps = 38.57552953833644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-02-16 13:10:34,247 | server.py:116 | fit progress: (4, 0.07358869695663452, {'accuracy': 0.1}, 1413.135594684)\n",
            "INFO:flwr:fit progress: (4, 0.07358869695663452, {'accuracy': 0.1}, 1413.135594684)\n",
            "DEBUG flwr 2023-02-16 13:10:34,255 | server.py:165 | evaluate_round 4: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07358869695663452 / accuracy 0.1\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 7] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:11:47,761 | server.py:179 | evaluate_round 4 received 7 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 7 results and 0 failures\n",
            "DEBUG flwr 2023-02-16 13:11:47,769 | server.py:215 | fit_round 5: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.297676 Acc@1: 10.546037 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.299384 Acc@1: 8.685119 (ε = 24.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.297818 Acc@1: 9.830766 (ε = 28.92, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.298006 Acc@1: 8.487892 (ε = 28.99, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.295766 Acc@1: 11.834798 (ε = 32.45, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.297314 Acc@1: 9.366513 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.295409 Acc@1: 10.663061 (ε = 35.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.296856 Acc@1: 9.380184 (ε = 35.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.295456 Acc@1: 11.710035 (ε = 38.43, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.295552 Acc@1: 10.113484 (ε = 38.47, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 5 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 2 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.297349 Acc@1: 9.998531 (ε = 19.74, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.297657 Acc@1: 10.632356 (ε = 24.81, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.296045 Acc@1: 10.330872 (ε = 24.72, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.296506 Acc@1: 10.420268 (ε = 28.99, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.295132 Acc@1: 9.875000 (ε = 28.81, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.296325 Acc@1: 10.397088 (ε = 32.45, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.295751 Acc@1: 10.288598 (ε = 32.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.296931 Acc@1: 10.230272 (ε = 35.61, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.295570 Acc@1: 10.190473 (ε = 35.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.296443 Acc@1: 9.866860 (ε = 38.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.294867 Acc@1: 10.257938 (ε = 38.45, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 6 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 8 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.296694 Acc@1: 10.474129 (ε = 19.65, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.296380 Acc@1: 11.031233 (ε = 25.00, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.298089 Acc@1: 9.994105 (ε = 24.90, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.296094 Acc@1: 10.158058 (ε = 28.89, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.298491 Acc@1: 9.098164 (ε = 28.89, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.295442 Acc@1: 10.318050 (ε = 32.43, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.296014 Acc@1: 10.236709 (ε = 32.43, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.295356 Acc@1: 10.628332 (ε = 35.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.296140 Acc@1: 9.812302 (ε = 35.63, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.295587 Acc@1: 9.701233 (ε = 38.39, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.294998 Acc@1: 10.513648 (ε = 38.47, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 9 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 4 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.296881 Acc@1: 9.582173 (ε = 20.00, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.296524 Acc@1: 9.522501 (ε = 28.94, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.295947 Acc@1: 9.566869 (ε = 35.50, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:17:06,274 | server.py:229 | fit_round 5 received 7 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 7 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 7 : eps = 38.57552953833644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-02-16 13:17:06,668 | server.py:116 | fit progress: (5, 0.07353930377960205, {'accuracy': 0.1}, 1805.5565929)\n",
            "INFO:flwr:fit progress: (5, 0.07353930377960205, {'accuracy': 0.1}, 1805.5565929)\n",
            "DEBUG flwr 2023-02-16 13:17:06,674 | server.py:165 | evaluate_round 5: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07353930377960205 / accuracy 0.1\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 5] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:18:18,523 | server.py:179 | evaluate_round 5 received 7 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 7 results and 0 failures\n",
            "DEBUG flwr 2023-02-16 13:18:18,525 | server.py:215 | fit_round 6: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 6] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 8236 MiB, 105 objects, write throughput 234 MiB/s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.296068 Acc@1: 9.100234 (ε = 19.74, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.296202 Acc@1: 9.476069 (ε = 24.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.294005 Acc@1: 10.490494 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.293673 Acc@1: 9.205878 (ε = 35.48, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.293028 Acc@1: 9.984369 (ε = 38.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 4 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.293674 Acc@1: 9.331224 (ε = 38.37, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 1 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.296195 Acc@1: 10.471390 (ε = 19.95, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.294849 Acc@1: 9.984659 (ε = 24.68, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.294287 Acc@1: 10.539736 (ε = 24.93, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.293540 Acc@1: 9.722872 (ε = 28.86, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.293824 Acc@1: 9.203632 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.294074 Acc@1: 10.787020 (ε = 32.33, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.293205 Acc@1: 9.737782 (ε = 35.63, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.294206 Acc@1: 10.407177 (ε = 38.47, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.292352 Acc@1: 9.541978 (ε = 38.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 6 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 7 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.295368 Acc@1: 10.080785 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.293907 Acc@1: 10.574381 (ε = 24.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.295452 Acc@1: 10.249734 (ε = 24.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.293359 Acc@1: 9.756379 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.293536 Acc@1: 10.397634 (ε = 32.36, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.292090 Acc@1: 10.057241 (ε = 35.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.293879 Acc@1: 9.610265 (ε = 38.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.292585 Acc@1: 10.172262 (ε = 38.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 0 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 8 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.296861 Acc@1: 9.182622 (ε = 19.91, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.294717 Acc@1: 10.468841 (ε = 24.65, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.295872 Acc@1: 9.862858 (ε = 28.84, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.294129 Acc@1: 9.933937 (ε = 35.52, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:23:27,992 | server.py:229 | fit_round 6 received 7 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 7 results and 0 failures\n",
            "INFO flwr 2023-02-16 13:23:28,185 | server.py:116 | fit progress: (6, 0.07347536087036133, {'accuracy': 0.1}, 2187.0735686549997)\n",
            "INFO:flwr:fit progress: (6, 0.07347536087036133, {'accuracy': 0.1}, 2187.0735686549997)\n",
            "DEBUG flwr 2023-02-16 13:23:28,190 | server.py:165 | evaluate_round 6: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 6: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 3 : eps = 38.57552953833644\n",
            "Server-side evaluation loss 0.07347536087036133 / accuracy 0.1\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 5] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:24:47,529 | server.py:179 | evaluate_round 6 received 7 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 6 received 7 results and 0 failures\n",
            "DEBUG flwr 2023-02-16 13:24:47,537 | server.py:215 | fit_round 7: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.293270 Acc@1: 9.917987 (ε = 19.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.293188 Acc@1: 8.917540 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.291800 Acc@1: 10.205870 (ε = 24.84, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.293434 Acc@1: 9.358950 (ε = 24.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.292303 Acc@1: 10.469338 (ε = 28.89, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.291977 Acc@1: 10.666831 (ε = 32.47, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.291298 Acc@1: 10.324189 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.290773 Acc@1: 9.801216 (ε = 35.45, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.290622 Acc@1: 11.273904 (ε = 38.45, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 1 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.288821 Acc@1: 10.504983 (ε = 38.56, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 9 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.293616 Acc@1: 9.912591 (ε = 20.00, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.293511 Acc@1: 9.164364 (ε = 20.00, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.292947 Acc@1: 9.963771 (ε = 24.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.293443 Acc@1: 9.185441 (ε = 24.81, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.290961 Acc@1: 11.352464 (ε = 28.86, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.292796 Acc@1: 8.658242 (ε = 28.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.291251 Acc@1: 9.949493 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.290591 Acc@1: 9.940868 (ε = 32.45, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.290585 Acc@1: 10.998036 (ε = 35.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.290749 Acc@1: 11.768720 (ε = 35.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.290459 Acc@1: 11.424727 (ε = 38.47, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.290588 Acc@1: 12.298512 (ε = 38.43, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 0 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 2 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.293419 Acc@1: 10.182611 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.295012 Acc@1: 9.452083 (ε = 19.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.291523 Acc@1: 10.611657 (ε = 24.93, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.291962 Acc@1: 9.767625 (ε = 24.90, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.292045 Acc@1: 10.145154 (ε = 28.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.291145 Acc@1: 10.743960 (ε = 28.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.292388 Acc@1: 9.941165 (ε = 32.38, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.289944 Acc@1: 11.237831 (ε = 35.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.289718 Acc@1: 10.591120 (ε = 35.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.289491 Acc@1: 11.323068 (ε = 38.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 5 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.290237 Acc@1: 9.905308 (ε = 38.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 3 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.293253 Acc@1: 10.262658 (ε = 19.65, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.293432 Acc@1: 10.609795 (ε = 24.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.291652 Acc@1: 9.909873 (ε = 32.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.291453 Acc@1: 10.769827 (ε = 35.63, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:30:07,948 | server.py:229 | fit_round 7 received 7 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 7 results and 0 failures\n",
            "INFO flwr 2023-02-16 13:30:08,151 | server.py:116 | fit progress: (7, 0.0733940806388855, {'accuracy': 0.112}, 2587.0395285080003)\n",
            "INFO:flwr:fit progress: (7, 0.0733940806388855, {'accuracy': 0.112}, 2587.0395285080003)\n",
            "DEBUG flwr 2023-02-16 13:30:08,156 | server.py:165 | evaluate_round 7: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 7: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 6 : eps = 38.57552953833644\n",
            "Server-side evaluation loss 0.0733940806388855 / accuracy 0.112\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:31:19,394 | server.py:179 | evaluate_round 7 received 7 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 7 received 7 results and 0 failures\n",
            "DEBUG flwr 2023-02-16 13:31:19,403 | server.py:215 | fit_round 8: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.290487 Acc@1: 10.645036 (ε = 19.74, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.290115 Acc@1: 10.580422 (ε = 24.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.288504 Acc@1: 12.930986 (ε = 32.45, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.287763 Acc@1: 11.275108 (ε = 38.43, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 1 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 2 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.289157 Acc@1: 11.726340 (ε = 19.69, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.290457 Acc@1: 11.046840 (ε = 19.91, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.289155 Acc@1: 10.878489 (ε = 24.90, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.289210 Acc@1: 12.781936 (ε = 28.81, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.288381 Acc@1: 12.150532 (ε = 28.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.287544 Acc@1: 12.928603 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.288242 Acc@1: 11.162783 (ε = 35.56, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.286492 Acc@1: 13.526758 (ε = 35.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.286291 Acc@1: 12.691988 (ε = 38.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.285955 Acc@1: 13.481576 (ε = 38.56, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 9 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 0 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.290235 Acc@1: 10.942553 (ε = 19.61, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.289701 Acc@1: 11.045001 (ε = 19.69, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.288793 Acc@1: 11.718785 (ε = 24.90, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.287243 Acc@1: 12.016319 (ε = 24.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.287878 Acc@1: 12.024473 (ε = 29.02, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.286457 Acc@1: 11.811551 (ε = 32.31, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.286193 Acc@1: 12.400565 (ε = 35.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.286062 Acc@1: 11.885760 (ε = 35.63, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.284785 Acc@1: 11.461362 (ε = 38.47, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 5 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.284325 Acc@1: 12.308284 (ε = 38.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 3 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.291427 Acc@1: 10.366067 (ε = 19.91, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.290307 Acc@1: 11.781819 (ε = 24.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.287582 Acc@1: 11.316963 (ε = 32.50, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:36:27,524 | server.py:229 | fit_round 8 received 7 results and 0 failures\n",
            "DEBUG:flwr:fit_round 8 received 7 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 6 : eps = 38.57552953833644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-02-16 13:36:27,797 | server.py:116 | fit progress: (8, 0.07329087018966675, {'accuracy': 0.128}, 2966.6855024019997)\n",
            "INFO:flwr:fit progress: (8, 0.07329087018966675, {'accuracy': 0.128}, 2966.6855024019997)\n",
            "DEBUG flwr 2023-02-16 13:36:27,803 | server.py:165 | evaluate_round 8: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 8: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07329087018966675 / accuracy 0.128\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 4] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:37:40,803 | server.py:179 | evaluate_round 8 received 7 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 8 received 7 results and 0 failures\n",
            "DEBUG flwr 2023-02-16 13:37:40,811 | server.py:215 | fit_round 9: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 9: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.285445 Acc@1: 13.176996 (ε = 19.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.285483 Acc@1: 12.308675 (ε = 19.82, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.283617 Acc@1: 13.574051 (ε = 25.00, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.284416 Acc@1: 12.861372 (ε = 24.68, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.282190 Acc@1: 14.344391 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.284584 Acc@1: 13.654683 (ε = 32.17, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.282226 Acc@1: 14.233071 (ε = 35.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.281005 Acc@1: 14.485521 (ε = 38.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 1 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 5 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.285759 Acc@1: 13.145234 (ε = 19.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.285355 Acc@1: 12.982730 (ε = 19.69, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.285615 Acc@1: 13.462765 (ε = 24.68, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.284634 Acc@1: 13.532902 (ε = 24.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.284736 Acc@1: 13.040580 (ε = 28.92, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.284396 Acc@1: 13.453760 (ε = 32.38, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.283246 Acc@1: 13.387373 (ε = 32.43, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.283521 Acc@1: 14.404983 (ε = 35.56, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.281919 Acc@1: 13.573307 (ε = 38.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 9 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.282148 Acc@1: 14.153521 (ε = 38.47, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 6 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.285277 Acc@1: 14.095449 (ε = 19.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.285412 Acc@1: 14.612444 (ε = 19.74, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.282914 Acc@1: 14.345773 (ε = 28.89, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.283430 Acc@1: 14.008198 (ε = 28.94, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.282098 Acc@1: 14.389244 (ε = 32.36, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.281302 Acc@1: 15.528861 (ε = 38.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.282216 Acc@1: 13.651109 (ε = 35.48, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 4 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.281550 Acc@1: 13.585306 (ε = 38.43, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 3 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.285182 Acc@1: 12.737871 (ε = 19.69, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.285005 Acc@1: 14.633999 (ε = 24.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.284368 Acc@1: 13.951850 (ε = 28.86, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.282883 Acc@1: 13.578445 (ε = 32.28, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.281222 Acc@1: 14.493113 (ε = 35.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.281174 Acc@1: 14.979647 (ε = 38.50, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:42:55,755 | server.py:229 | fit_round 9 received 7 results and 0 failures\n",
            "DEBUG:flwr:fit_round 9 received 7 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 0 : eps = 38.57552953833644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-02-16 13:42:56,043 | server.py:116 | fit progress: (9, 0.07316101360321045, {'accuracy': 0.13}, 3354.931632801)\n",
            "INFO:flwr:fit progress: (9, 0.07316101360321045, {'accuracy': 0.13}, 3354.931632801)\n",
            "DEBUG flwr 2023-02-16 13:42:56,051 | server.py:165 | evaluate_round 9: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 9: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07316101360321045 / accuracy 0.13\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:44:08,275 | server.py:179 | evaluate_round 9 received 7 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 9 received 7 results and 0 failures\n",
            "DEBUG flwr 2023-02-16 13:44:08,278 | server.py:215 | fit_round 10: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 10: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.283304 Acc@1: 14.106162 (ε = 19.65, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.279791 Acc@1: 14.138373 (ε = 19.95, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.278410 Acc@1: 13.904234 (ε = 24.81, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.279861 Acc@1: 14.902011 (ε = 28.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.279032 Acc@1: 15.645680 (ε = 32.47, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.274461 Acc@1: 15.967074 (ε = 32.50, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.274728 Acc@1: 15.933561 (ε = 35.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.278201 Acc@1: 15.661481 (ε = 35.56, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.271916 Acc@1: 16.031169 (ε = 38.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.276874 Acc@1: 14.835237 (ε = 38.47, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 7 : eps = 38.57552953833644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 16619 MiB, 206 objects, write throughput 230 MiB/s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 6 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.279129 Acc@1: 15.414760 (ε = 19.82, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.278905 Acc@1: 15.776152 (ε = 20.00, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.279213 Acc@1: 15.053044 (ε = 24.84, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.277974 Acc@1: 16.287857 (ε = 24.81, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.276237 Acc@1: 16.169143 (ε = 28.99, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.276867 Acc@1: 16.492169 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.276331 Acc@1: 15.140436 (ε = 35.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.274216 Acc@1: 17.254428 (ε = 35.41, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.273157 Acc@1: 15.572821 (ε = 38.45, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 5 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.274153 Acc@1: 16.647565 (ε = 38.54, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 8 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.281213 Acc@1: 13.669611 (ε = 19.91, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.280832 Acc@1: 15.704148 (ε = 19.56, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.281435 Acc@1: 14.627583 (ε = 24.87, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 1 \tLoss: 2.279309 Acc@1: 15.407267 (ε = 24.78, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.277140 Acc@1: 15.681388 (ε = 28.89, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.279811 Acc@1: 15.376686 (ε = 29.02, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.276594 Acc@1: 16.685818 (ε = 32.45, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.277611 Acc@1: 16.341390 (ε = 32.38, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.277323 Acc@1: 17.275179 (ε = 35.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.276831 Acc@1: 15.849696 (ε = 35.52, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 1 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.276004 Acc@1: 17.497130 (ε = 38.58, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=624)\u001b[0m epsilon of client 4 : eps = 38.57552953833644\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 0 \tLoss: 2.278887 Acc@1: 15.678593 (ε = 19.61, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 2 \tLoss: 2.277864 Acc@1: 16.003295 (ε = 28.97, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 3 \tLoss: 2.278673 Acc@1: 14.980689 (ε = 32.40, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 4 \tLoss: 2.275345 Acc@1: 17.233070 (ε = 35.61, δ = 1e-05)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m \tTrain Epoch: 5 \tLoss: 2.275855 Acc@1: 17.035589 (ε = 38.37, δ = 1e-05)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:49:22,385 | server.py:229 | fit_round 10 received 7 results and 0 failures\n",
            "DEBUG:flwr:fit_round 10 received 7 results and 0 failures\n",
            "INFO flwr 2023-02-16 13:49:22,580 | server.py:116 | fit progress: (10, 0.07300526762008668, {'accuracy': 0.142}, 3741.4687943930003)\n",
            "INFO:flwr:fit progress: (10, 0.07300526762008668, {'accuracy': 0.142}, 3741.4687943930003)\n",
            "DEBUG flwr 2023-02-16 13:49:22,589 | server.py:165 | evaluate_round 10: strategy sampled 7 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 10: strategy sampled 7 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=625)\u001b[0m epsilon of client 0 : eps = 38.57552953833644\n",
            "Server-side evaluation loss 0.07300526762008668 / accuracy 0.142\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=625)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=624)\u001b[0m [Client 5] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-02-16 13:50:33,511 | server.py:179 | evaluate_round 10 received 7 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 10 received 7 results and 0 failures\n",
            "INFO flwr 2023-02-16 13:50:33,513 | server.py:144 | FL finished in 3812.4013537640003\n",
            "INFO:flwr:FL finished in 3812.4013537640003\n",
            "INFO flwr 2023-02-16 13:50:33,515 | app.py:202 | app_fit: losses_distributed [(1, 0.07363850232533045), (2, 0.07362863656452724), (3, 0.07357161671774727), (4, 0.07351281016213553), (5, 0.07343416316168648), (6, 0.07337530054364885), (7, 0.07328757006781442), (8, 0.0731219014440264), (9, 0.07303135408673968), (10, 0.07280791848046439)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.07363850232533045), (2, 0.07362863656452724), (3, 0.07357161671774727), (4, 0.07351281016213553), (5, 0.07343416316168648), (6, 0.07337530054364885), (7, 0.07328757006781442), (8, 0.0731219014440264), (9, 0.07303135408673968), (10, 0.07280791848046439)]\n",
            "INFO flwr 2023-02-16 13:50:33,517 | app.py:203 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-02-16 13:50:33,522 | app.py:204 | app_fit: losses_centralized [(0, 0.07371957349777222), (1, 0.07369145441055298), (2, 0.07366289901733399), (3, 0.07362965869903565), (4, 0.07358869695663452), (5, 0.07353930377960205), (6, 0.07347536087036133), (7, 0.0733940806388855), (8, 0.07329087018966675), (9, 0.07316101360321045), (10, 0.07300526762008668)]\n",
            "INFO:flwr:app_fit: losses_centralized [(0, 0.07371957349777222), (1, 0.07369145441055298), (2, 0.07366289901733399), (3, 0.07362965869903565), (4, 0.07358869695663452), (5, 0.07353930377960205), (6, 0.07347536087036133), (7, 0.0733940806388855), (8, 0.07329087018966675), (9, 0.07316101360321045), (10, 0.07300526762008668)]\n",
            "INFO flwr 2023-02-16 13:50:33,524 | app.py:205 | app_fit: metrics_centralized {'accuracy': [(0, 0.1), (1, 0.1), (2, 0.1), (3, 0.1), (4, 0.1), (5, 0.1), (6, 0.1), (7, 0.112), (8, 0.128), (9, 0.13), (10, 0.142)]}\n",
            "INFO:flwr:app_fit: metrics_centralized {'accuracy': [(0, 0.1), (1, 0.1), (2, 0.1), (3, 0.1), (4, 0.1), (5, 0.1), (6, 0.1), (7, 0.112), (8, 0.128), (9, 0.13), (10, 0.142)]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.07363850232533045\n",
              "\tround 2: 0.07362863656452724\n",
              "\tround 3: 0.07357161671774727\n",
              "\tround 4: 0.07351281016213553\n",
              "\tround 5: 0.07343416316168648\n",
              "\tround 6: 0.07337530054364885\n",
              "\tround 7: 0.07328757006781442\n",
              "\tround 8: 0.0731219014440264\n",
              "\tround 9: 0.07303135408673968\n",
              "\tround 10: 0.07280791848046439\n",
              "History (loss, centralized):\n",
              "\tround 0: 0.07371957349777222\n",
              "\tround 1: 0.07369145441055298\n",
              "\tround 2: 0.07366289901733399\n",
              "\tround 3: 0.07362965869903565\n",
              "\tround 4: 0.07358869695663452\n",
              "\tround 5: 0.07353930377960205\n",
              "\tround 6: 0.07347536087036133\n",
              "\tround 7: 0.0733940806388855\n",
              "\tround 8: 0.07329087018966675\n",
              "\tround 9: 0.07316101360321045\n",
              "\tround 10: 0.07300526762008668\n",
              "History (metrics, centralized):\n",
              "{'accuracy': [(0, 0.1), (1, 0.1), (2, 0.1), (3, 0.1), (4, 0.1), (5, 0.1), (6, 0.1), (7, 0.112), (8, 0.128), (9, 0.13), (10, 0.142)]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.7,  \n",
        "    fraction_evaluate=0.7,  \n",
        "    min_fit_clients=4,\n",
        "    min_evaluate_clients=4,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        "    evaluate_fn=evaluate,  # Pass the evaluation function\n",
        ")\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=10),  # 10 rounds\n",
        "    strategy=strategy,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_gk3HjOufcK",
        "outputId": "7d1dbd13-e7cc-47ff-e332-774f05c12659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 0.14202568185329437\n",
            "accuracy = 0.1646\n"
          ]
        }
      ],
      "source": [
        "#test the global model after the federated training\n",
        "loss, acc = test(global_model,testloader,DEVICE)\n",
        "print(f'loss = {loss}')\n",
        "print(f'accuracy = {acc}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QK2kXpCmjYCi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "a6202d1482f480674d090d9d9b5c400c9026d296d041bf38196c7cb6353a393f"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6648616fbe7a4280945e57de1277e30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc76aa5f101946f2920747a661659ef6",
              "IPY_MODEL_672162bb77a2426eafd3e73af4e29234",
              "IPY_MODEL_aeb6a80e16534aaf9ade4e7b6c9147fd"
            ],
            "layout": "IPY_MODEL_569f1567ffcf4e12867239dc20e93d3b"
          }
        },
        "cc76aa5f101946f2920747a661659ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c106229a7524eb8ac191c162ece4fbd",
            "placeholder": "​",
            "style": "IPY_MODEL_7b1828db76404ac6ab0b9b0d65cb210b",
            "value": "100%"
          }
        },
        "672162bb77a2426eafd3e73af4e29234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78d56869bb524a688b77970084884ee8",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_588a11d7872a4f0daa780431fbba6088",
            "value": 170498071
          }
        },
        "aeb6a80e16534aaf9ade4e7b6c9147fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f82560a209d6453682b5a5d007b703b0",
            "placeholder": "​",
            "style": "IPY_MODEL_15595f5ff69d4f6db996ad7313626ef1",
            "value": " 170498071/170498071 [00:02&lt;00:00, 87621853.28it/s]"
          }
        },
        "569f1567ffcf4e12867239dc20e93d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c106229a7524eb8ac191c162ece4fbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b1828db76404ac6ab0b9b0d65cb210b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78d56869bb524a688b77970084884ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588a11d7872a4f0daa780431fbba6088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f82560a209d6453682b5a5d007b703b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15595f5ff69d4f6db996ad7313626ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}